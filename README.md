# Deep Learning Journey

## 📑 Table of Contents

- [📘 About](#-about)
- [📚 Course Content](#-course-content)
- [🧠 What I've Learned](#-what-ive-learned)
- [📖 Supplementary Reading](#-supplementary-reading)
- [🎓 Certificate](#-certificate)

## 📘 About

This repository documents my self-study of Deep Learning through an online Udemy course: **[The Complete Neural Networks Bootcamp: Theory, Applications](https://www.udemy.com/course/the-complete-neural-networks-bootcamp-theory-applications/)** covering core topics like MLP, CNN, RNN, Transformers, and modern applications such as NLP, CV, and LLMs.

## 🧠 What I've Learned

## 📖 Supplementary Reading

## 🎓 Certificate

## 📚 Course content

| Section    | Title            | Summary                                                                                                       | Note and Code                |
|------------|------------------|---------------------------------------------------------------------------------------------------------------|------------------------------|
| 1  | How Neural Networks and Backpropagation Works     | - Theory of Gradient Descent & Propagation<br>- Fwd/Bwd  calculating for a MLP | ✍️ [Written](https://github.com/laikhanhhoang/Deep_Learning_Journey/blob/main/Lecture_Note/Section%201%20-%20How%20Neural%20Networks%20and%20Back%20Propagation%20Work.pdf) <br>💻 No code|
|2| Loss Functions| - MSE, MAE, Huber Loss, Binary Cross Entropy, Softmax Function, KL Divergence, Hinge Loss, Triplet Ranking Loss <br> - Pros, cons, and real-world applications of the above loss functions| ✍️ [Written](---) <br>💻 No code|


